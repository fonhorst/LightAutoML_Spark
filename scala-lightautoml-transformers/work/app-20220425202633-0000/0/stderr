Spark Executor Command: "/home/nikolay/.jdks/corretto-11.0.13/bin/java" "-cp" "/home/nikolay/wspace/LightAutoML/scala-lightautoml-transformers/./conf:/home/nikolay/wspace/LightAutoML/scala-lightautoml-transformers/./assembly/target/scala-2.12/jars/*" "-Xmx1024M" "-Dspark.driver.port=45691" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@127.0.0.1:45691" "--executor-id" "0" "--hostname" "192.168.3.5" "--cores" "2" "--app-id" "app-20220425202633-0000" "--worker-url" "spark://Worker@192.168.3.5:45399"
========================================

Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/04/25 20:26:34 INFO CoarseGrainedExecutorBackend: Started daemon with process name: 119039@localhost.localdomain
22/04/25 20:26:34 INFO SignalUtils: Registering signal handler for TERM
22/04/25 20:26:34 INFO SignalUtils: Registering signal handler for HUP
22/04/25 20:26:34 INFO SignalUtils: Registering signal handler for INT
22/04/25 20:26:35 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 192.168.3.5 instead (on interface wlp0s20f3)
22/04/25 20:26:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/nikolay/.cache/pypoetry/virtualenvs/lightautoml-749ciRtl-py3.9/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
22/04/25 20:26:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/04/25 20:26:35 INFO SecurityManager: Changing view acls to: nikolay
22/04/25 20:26:35 INFO SecurityManager: Changing modify acls to: nikolay
22/04/25 20:26:35 INFO SecurityManager: Changing view acls groups to: 
22/04/25 20:26:35 INFO SecurityManager: Changing modify acls groups to: 
22/04/25 20:26:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nikolay); groups with view permissions: Set(); users  with modify permissions: Set(nikolay); groups with modify permissions: Set()
22/04/25 20:26:36 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:45691 after 123 ms (0 ms spent in bootstraps)
22/04/25 20:26:36 INFO SecurityManager: Changing view acls to: nikolay
22/04/25 20:26:36 INFO SecurityManager: Changing modify acls to: nikolay
22/04/25 20:26:36 INFO SecurityManager: Changing view acls groups to: 
22/04/25 20:26:36 INFO SecurityManager: Changing modify acls groups to: 
22/04/25 20:26:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(nikolay); groups with view permissions: Set(); users  with modify permissions: Set(nikolay); groups with modify permissions: Set()
22/04/25 20:26:36 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:45691 after 9 ms (0 ms spent in bootstraps)
22/04/25 20:26:36 INFO DiskBlockManager: Created local directory at /tmp/spark-01f6d43d-27cb-42c6-8753-27c3057951aa/executor-b84df66e-d6e3-472c-8de7-2ce9b52934b4/blockmgr-6aed5ec5-cb8a-42af-a8c4-cbbcf3323601
22/04/25 20:26:36 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
22/04/25 20:26:37 INFO WorkerWatcher: Connecting to worker spark://Worker@192.168.3.5:45399
22/04/25 20:26:37 INFO CoarseGrainedExecutorBackend: Connecting to driver: spark://CoarseGrainedScheduler@127.0.0.1:45691
22/04/25 20:26:37 INFO TransportClientFactory: Successfully created connection to /192.168.3.5:45399 after 30 ms (0 ms spent in bootstraps)
22/04/25 20:26:37 INFO WorkerWatcher: Successfully connected to spark://Worker@192.168.3.5:45399
22/04/25 20:26:37 INFO ResourceUtils: ==============================================================
22/04/25 20:26:37 INFO ResourceUtils: No custom resources configured for spark.executor.
22/04/25 20:26:37 INFO ResourceUtils: ==============================================================
22/04/25 20:26:37 INFO CoarseGrainedExecutorBackend: Successfully registered with driver
22/04/25 20:26:37 INFO Executor: Starting executor ID 0 on host 192.168.3.5
22/04/25 20:26:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39977.
22/04/25 20:26:37 INFO NettyBlockTransferService: Server created on 192.168.3.5:39977
22/04/25 20:26:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/04/25 20:26:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(0, 192.168.3.5, 39977, None)
22/04/25 20:26:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(0, 192.168.3.5, 39977, None)
22/04/25 20:26:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(0, 192.168.3.5, 39977, None)
22/04/25 20:26:37 INFO Executor: Fetching spark://127.0.0.1:45691/jars/spark-lightautoml_2.12-0.1.jar with timestamp 1650907591647
22/04/25 20:26:37 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:45691 after 9 ms (0 ms spent in bootstraps)
22/04/25 20:26:37 INFO Utils: Fetching spark://127.0.0.1:45691/jars/spark-lightautoml_2.12-0.1.jar to /tmp/spark-01f6d43d-27cb-42c6-8753-27c3057951aa/executor-b84df66e-d6e3-472c-8de7-2ce9b52934b4/spark-3e53b2e2-4fd4-4f31-83c0-180557d3c1c9/fetchFileTemp5995952516683004533.tmp
22/04/25 20:26:37 INFO Utils: Copying /tmp/spark-01f6d43d-27cb-42c6-8753-27c3057951aa/executor-b84df66e-d6e3-472c-8de7-2ce9b52934b4/spark-3e53b2e2-4fd4-4f31-83c0-180557d3c1c9/6199607581650907591647_cache to /home/nikolay/wspace/LightAutoML/scala-lightautoml-transformers/work/app-20220425202633-0000/0/./spark-lightautoml_2.12-0.1.jar
22/04/25 20:26:37 INFO Executor: Adding file:/home/nikolay/wspace/LightAutoML/scala-lightautoml-transformers/work/app-20220425202633-0000/0/./spark-lightautoml_2.12-0.1.jar to class loader
22/04/25 20:26:39 INFO CoarseGrainedExecutorBackend: Got assigned task 0
22/04/25 20:26:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
22/04/25 20:26:39 INFO TorrentBroadcast: Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
22/04/25 20:26:39 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:44839 after 2 ms (0 ms spent in bootstraps)
22/04/25 20:26:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 16.0 KiB, free 434.4 MiB)
22/04/25 20:26:39 INFO TorrentBroadcast: Reading broadcast variable 0 took 100 ms
22/04/25 20:26:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 48.6 KiB, free 434.3 MiB)
22/04/25 20:26:40 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD
	at java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2205)
	at java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2168)
	at java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1422)
	at java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2480)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2387)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1175)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2325)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1175)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2325)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:85)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
22/04/25 20:26:41 ERROR CoarseGrainedExecutorBackend: RECEIVED SIGNAL TERM
)
java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field org.apache.spark.rdd.RDD.dependencies_ of type scala.collection.Seq in instance of org.apache.spark.rdd.MapPartitionsRDD
	at java.base/java.io.ObjectStreamClass$FieldReflector.setObjFieldValues(ObjectStreamClass.java:2205)
	at java.base/java.io.ObjectStreamClass$FieldReflector.checkObjectFieldValueTypes(ObjectStreamClass.java:2168)
	at java.base/java.io.ObjectStreamClass.checkObjFieldValueTypes(ObjectStreamClass.java:1422)
	at java.base/java.io.ObjectInputStream.defaultCheckFieldValues(ObjectInputStream.java:2480)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2387)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1175)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2325)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at scala.collection.immutable.List$SerializationProxy.readObject(List.scala:527)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at java.base/java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:1175)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2325)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2464)
	at java.base/java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2358)
	at java.base/java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2196)
	at java.base/java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1679)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:493)
	at java.base/java.io.ObjectInputStream.readObject(ObjectInputStream.java:451)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.JavaSerializerInstance.deserialize(JavaSerializer.scala:115)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:85)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)
	at org.apache.spark.scheduler.Task.run(Task.scala:131)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
