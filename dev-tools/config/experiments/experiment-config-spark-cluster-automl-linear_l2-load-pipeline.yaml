---
experiment_type: spark_quality
calculation_scripts:
  spark: dev-tools/experiments/spark_experiments.py
  lama: dev-tools/experiments/lama_experiments.py
state_file: 'delete'  # Available values are 'use|ignore|delete', use - skip experiments in state file, ignore - don`t skip experiments, delete - delete experiments in state file

# Unique set of parameters for each experiment
experiments:
  - name: "infer_linear_l2_100M_32e_32g" # automl_linear_l2_96M_4e_128g
    library: [ "spark" ]
    repeat_rate: 1
    params:
      func: [ "load_and_predict_automl" ]
      dataset: [ "used_cars_dataset_1x" ] # used_cars_dataset_1x
      seed: [ 42 ]
      cv: [ 3 ]
      use_algos:
        - [ [ "linear_l2" ] ]
      dataset_increase_factor: [ 170 ] # 17    x17 - 10.2M
      automl_model_path: [ '/mnt/nfs/spark-lama-pipelines/automl_linear_l2_pipeline' ] # 'hdfs://node21.bdcl:9000/automl_linear_l2_pipeline'
    spark_config:
      spark.executor.instances: [ '32' ] # '1', '2', '4', '8', '16', '32'
      spark.executor.cores: [ '8' ]
      spark.executor.memory: [ '32g' ]
